# -*- coding: utf-8 -*-
"""defogging.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LaBasYtG8fsA4FytJL_LJOwhlc5XT9iZ
"""

from google.colab import drive
drive.mount('/content/drive')

import torch
import torch.nn as nn

class ChannelAttention(nn.Module):
    def __init__(self, in_channels, reduction_ratio=16):
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc1 = nn.Conv2d(in_channels, in_channels // reduction_ratio, kernel_size=1, padding=0)
        self.relu = nn.ReLU()
        self.fc2 = nn.Conv2d(in_channels // reduction_ratio, in_channels, kernel_size=1, padding=0)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.fc2(self.relu(self.fc1(self.avg_pool(x))))
        out = self.sigmoid(avg_out)
        ca_output = x * out
        return ca_output

class PixelAttention(nn.Module):
    def __init__(self, in_channels):
        super(PixelAttention, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=1, padding=0)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(in_channels, 1, kernel_size=1, padding=0)
        self.sigmoid = nn.Sigmoid()

    def forward(self,ca_output ):
        # Apply two convolutional layers with ReLU and sigmoid activations
        attention = self.relu(self.conv1(ca_output))
        attention = self.sigmoid(self.conv2(attention))

        # Reshape to match input channels (C*H*W) if necessary
        if attention.shape[1] != ca_output.shape[1]:
            attention = attention.unsqueeze(1)  # Add a channel dimension

        # Element-wise multiplication
        pa_output = ca_output * attention
        return pa_output

class BasicAttentionBlock(nn.Module):
    def __init__(self, in_channels):
        super(BasicAttentionBlock, self).__init__()
        # Initial convolution and ReLU
        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)
        self.relu = nn.ReLU(inplace=False)
        # Convolution and sigmoid for intermediate weights
        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)
        self.sigmoid = nn.Sigmoid()
        # Channel attention block (adapted from previous code)
        self.ca = ChannelAttention(in_channels)
        # Pixel attention block (adapted from previous code)
        self.pa = PixelAttention(in_channels)

    def forward(self, x):
        # Initial attention using convolution and ReLU
        attention1 = self.relu(self.conv1(x))
        # Element-wise sum with input
        out = x + attention1

        # Intermediate attention using convolution and sigmoid
        attention2 = self.conv2(out)

        # Apply channel attention
        out = self.ca(out)

        # Apply pixel attention
        out = self.pa(out)

        # Final attention using element-wise sum
        bab_ouput = x + out
        return bab_ouput

class BasicAttentionModule(nn.Module):
    def __init__(self, in_channels, out_channels, upsample_scale=2):
        super(BasicAttentionModule, self).__init__()
        # Basic attention block
        self.bab = BasicAttentionBlock(in_channels)
        # Max pooling layer
        self.max_pool = nn.MaxPool2d(kernel_size=2)
        # Upsampling layer
        self.upsample = nn.Upsample(scale_factor=upsample_scale, mode='bilinear')

    def forward(self, x):
        # Apply basic attention block
        out = self.bab(x)
        # Perform max pooling
        out = self.max_pool(out)
        # Upsample to original size
        out = self.upsample(out)
        bmu_ouput = out
        return bmu_ouput

import tensorflow as tf

def depthwise_conv_block(inputs, filters, kernel_size, strides=1):
    # Depthwise convolution
    x = tf.keras.layers.DepthwiseConv2D(kernel_size, strides=strides, padding='same')(inputs)
    x = tf.keras.layers.BatchNormalization()(x)

    # Pointwise convolution
    x = tf.keras.layers.Conv2D(filters, kernel_size=1, strides=1, padding='same')(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.Activation('relu')(x)

    return x

# Define the input shape
input_shape = (224, 224, 3)  # Example input shape, change according to your images

# Define your model
inputs = tf.keras.Input(shape=input_shape)
outputs = depthwise_conv_block(inputs, filters=64, kernel_size=3, strides=1)
model = tf.keras.Model(inputs, outputs)

# Compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Load images from a directory
train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

train_generator = train_datagen.flow_from_directory(
    '/path/to/dataset',  # Path to your dataset directory
    target_size=(224, 224),  # Resize images to 224x224
    batch_size=32,
    class_mode='binary'  # Change this based on your task (e.g., 'binary', 'categorical')
)

# Train the model
model.fit(train_generator, epochs=10)

import tensorflow as tf

def pointwise_conv_block(inputs, filters):
    # Pointwise convolution
    x = tf.keras.layers.Conv2D(filters, kernel_size=1, strides=1, padding='same')(inputs)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.Activation('relu')(x)

    return x

# Define the input shape
input_shape = (224, 224, 3)  # Example input shape, change according to your images

# Define the model
inputs = tf.keras.Input(shape=input_shape)
outputs = pointwise_conv_block(inputs, filters=64)
model = tf.keras.Model(inputs, outputs)

# Compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Load images from a directory
train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

train_generator = train_datagen.flow_from_directory(
    '/path/to/dataset',  # Path to your dataset directory
    target_size=(224, 224),  # Resize images to 224x224
    batch_size=32,
    class_mode='binary'  # Change this based on your task (e.g., 'binary', 'categorical')
)

# Train the model
model.fit(train_generator, epochs=10)

import tensorflow as tf

def ds_conv1(inputs, filters, kernel_size, strides=1):
    # Depthwise convolution
    x = tf.keras.layers.DepthwiseConv2D(kernel_size, strides=strides, padding='same')(inputs)
    x = tf.keras.layers.BatchNormalization()(x)

    # Pointwise convolution
    x = tf.keras.layers.Conv2D(filters, kernel_size=1, strides=1, padding='same')(x)
    x = tf.keras.layers.BatchNormalization()(x)

    # ReLU activation
    x = tf.keras.layers.Activation('relu')(x)

    return x

# Define the input shape
input_shape = (224, 224, 3)  # Example input shape, change according to your images

# Define the model
inputs = tf.keras.Input(shape=input_shape)
outputs = ds_conv1(inputs, filters=64, kernel_size=3, strides=1)
model = tf.keras.Model(inputs, outputs)

# Compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Load images from a directory
train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

train_generator = train_datagen.flow_from_directory(
    '/path/to/dataset',  # Path to your dataset directory
    target_size=(224, 224),  # Resize images to 224x224
    batch_size=32,
    class_mode='binary'  # Change this based on your task
)

# Train the model
model.fit(train_generator, epochs=10)

import tensorflow as tf

def ds_conv2(inputs, filters, kernel_size, strides=1):
    # Depthwise convolution
    x = tf.keras.layers.DepthwiseConv2D(kernel_size, strides=strides, padding='same')(inputs)
    x = tf.keras.layers.BatchNormalization()(x)

    # Pointwise convolution
    x = tf.keras.layers.Conv2D(filters, kernel_size=1, strides=1, padding='same')(x)
    x = tf.keras.layers.BatchNormalization()(x)

    # Sigmoid activation
    x = tf.keras.layers.Activation('sigmoid')(x)

    return x

# Define the input shape
input_shape = (224, 224, 3)  # Example input shape, change according to your images

# Define the model
inputs = tf.keras.Input(shape=input_shape)
outputs = ds_conv1(inputs, filters=64, kernel_size=3, strides=1)
model = tf.keras.Model(inputs, outputs)

# Compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Load images from a directory
train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

train_generator = train_datagen.flow_from_directory(
    '/path/to/dataset',  # Path to your dataset directory
    target_size=(224, 224),  # Resize images to 224x224
    batch_size=32,
    class_mode='binary'  # Change this based on your task
)

# Train the model
model.fit(train_generator, epochs=10)

# Define the input shape
input_shape = (224, 224, 3)  # Example input shape, change according to your images

# Define the model
inputs = tf.keras.Input(shape=input_shape)

# First ds_conv1 and bmu_block
x = ds_conv1(inputs, filters=64, kernel_size=3)
x = BasicAttentionModule(x, filters=64)

# Second ds_conv1 and bmu_block
x = ds_conv1(x, filters=128, kernel_size=3)
x = BasicAttentionModule(x, filters=128)

# Third ds_conv1 and bmu_block
x = ds_conv1(x, filters=256, kernel_size=3)
x = BasicAttentionModule(x, filters=256)

# Final ds_conv1
outputs = ds_conv1(x, filters=512, kernel_size=3)

model = tf.keras.Model(inputs, outputs)

# Compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Load images from a directory
train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

train_generator = train_datagen.flow_from_directory(
    '/path/to/dataset',  # Path to your dataset directory
    target_size=(224, 224),  # Resize images to 224x224
    batch_size=32,
    class_mode='binary'  # Change this based on your task
)

# Train the model
model.fit(train_generator, epochs=10)